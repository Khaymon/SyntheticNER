{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELED_DATA_PATH = \"./data/Baseline/\"\n",
    "# persons_files = glob.glob(os.path.join(LABELED_DATA_PATH, \"PER*\"))\n",
    "TRAIN_PATH = \"train_sents.csv\"\n",
    "TEST_PATH = \"test_sents.csv\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH, index_col=0)\n",
    "test_df = pd.read_csv(TEST_PATH, index_col=0)\n",
    "\n",
    "train_df = train_df.drop([\"gender\"], axis=1)\n",
    "test_df = test_df.drop([\"gender\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bio_labels(sentences):\n",
    "    all_labels = []\n",
    "    all_sentences = []\n",
    "    for sentence in tqdm(sentences):\n",
    "        current_labels = []\n",
    "        current_sentence = []\n",
    "        ptr = 0\n",
    "        while ptr < len(sentence):\n",
    "            if sentence[ptr] == \"|O|\" or sentence[ptr] == \"|P|\" or sentence[ptr] == \"|L|\":\n",
    "                ptr += 1\n",
    "                continue\n",
    "            current_sentence.append(sentence[ptr])\n",
    "            if ptr + 1 == len(sentence):\n",
    "                current_labels.append(\"O\")\n",
    "            else:\n",
    "                if sentence[ptr + 1] == \"|O|\":\n",
    "                    if current_labels and current_labels[-1] in (\"B_ORG\", \"I_ORG\"):\n",
    "                        current_labels.append(\"I_ORG\")\n",
    "                    else:\n",
    "                        current_labels.append(\"B_ORG\")\n",
    "                elif sentence[ptr + 1] == \"|L|\":\n",
    "                    if current_labels and current_labels[-1] in (\"B_LOC\", \"I_LOC\"):\n",
    "                        current_labels.append(\"I_LOC\")\n",
    "                    else:\n",
    "                        current_labels.append(\"B_LOC\")\n",
    "                elif sentence[ptr + 1] == \"|P|\":\n",
    "                    if current_labels and current_labels[-1] in (\"B_PER\", \"I_PER\"):\n",
    "                        current_labels.append(\"I_PER\")\n",
    "                    else:\n",
    "                        current_labels.append(\"B_PER\")\n",
    "                else:\n",
    "                    current_labels.append(\"O\")\n",
    "            ptr += 1\n",
    "        all_labels.append(current_labels)\n",
    "        all_sentences.append(current_sentence)\n",
    "    \n",
    "    return all_sentences, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markup_sentences(sents: pd.DataFrame):\n",
    "    languages = {}\n",
    "\n",
    "    for language in sents.columns:\n",
    "        sentences = sents[language]\n",
    "        # sentences = sentences.str.replace('.', ' . ')\n",
    "        # sentences = sentences.str.replace(',', ' , ')\n",
    "        # sentences = sentences.str.replace('(', ' ( ')\n",
    "        # sentences = sentences.str.replace(')', ' ) ')\n",
    "        # sentences = sentences.str.replace('«', ' « ')\n",
    "        # sentences = sentences.str.replace('»', ' » ')\n",
    "        tk = WhitespaceTokenizer()\n",
    "        tokenized = sentences.apply(tk.tokenize)\n",
    "        sentences, labels = get_bio_labels(tokenized)\n",
    "        \n",
    "        languages[language] = {\n",
    "            \"tokens\": sentences,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        \n",
    "    for language in languages:\n",
    "        assert len(languages[language][\"tokens\"]) == len(languages[language][\"labels\"])\n",
    "        \n",
    "    return pd.DataFrame(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8595/8595 [00:00<00:00, 74821.18it/s]\n",
      "100%|██████████| 8595/8595 [00:00<00:00, 81499.41it/s]\n",
      "100%|██████████| 8595/8595 [00:00<00:00, 81496.83it/s]\n",
      "100%|██████████| 8595/8595 [00:00<00:00, 94794.20it/s]\n",
      "100%|██████████| 8595/8595 [00:00<00:00, 72344.47it/s]\n",
      "100%|██████████| 8595/8595 [00:00<00:00, 36551.64it/s]\n",
      "100%|██████████| 8595/8595 [00:00<00:00, 72071.69it/s]\n",
      "100%|██████████| 8595/8595 [00:00<00:00, 68836.28it/s]\n",
      "100%|██████████| 8595/8595 [00:00<00:00, 64080.19it/s]\n",
      "100%|██████████| 8595/8595 [00:00<00:00, 34378.72it/s]\n",
      "100%|██████████| 8595/8595 [00:00<00:00, 75136.82it/s]\n",
      "100%|██████████| 2149/2149 [00:00<00:00, 82628.01it/s]\n",
      "100%|██████████| 2149/2149 [00:00<00:00, 79286.78it/s]\n",
      "100%|██████████| 2149/2149 [00:00<00:00, 79433.52it/s]\n",
      "100%|██████████| 2149/2149 [00:00<00:00, 76910.78it/s]\n",
      "100%|██████████| 2149/2149 [00:00<00:00, 76745.11it/s]\n",
      "100%|██████████| 2149/2149 [00:00<00:00, 86344.22it/s]\n",
      "100%|██████████| 2149/2149 [00:00<00:00, 65333.16it/s]\n",
      "100%|██████████| 2149/2149 [00:00<00:00, 58129.12it/s]\n",
      "100%|██████████| 2149/2149 [00:00<00:00, 47318.25it/s]\n",
      "100%|██████████| 2149/2149 [00:00<00:00, 59098.72it/s]\n",
      "100%|██████████| 2149/2149 [00:00<00:00, 9038.64it/s]\n"
     ]
    }
   ],
   "source": [
    "train_markup = markup_sentences(train_df)\n",
    "test_markup = markup_sentences(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_markup.to_csv(\"train_markup.csv\")\n",
    "test_markup.to_csv(\"test_markup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
